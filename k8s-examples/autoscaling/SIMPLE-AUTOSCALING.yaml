# SIMPLE Autoscaling - Just What You Need
# Problem: Traffic goes up → App slows down → Users unhappy
# Solution: Automatically add more pods when busy

# =================== BASIC SETUP ===================

# 1. Your app (MUST have resource requests)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: app
        image: nginx:1.21
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 100m        # REQUIRED for autoscaling
            memory: 128Mi    # REQUIRED for autoscaling
          limits:
            cpu: 500m
            memory: 512Mi

---
# 2. Service to expose your app
apiVersion: v1
kind: Service
metadata:
  name: my-app-service
spec:
  selector:
    app: my-app
  ports:
  - port: 80
    targetPort: 80

---
# 3. HPA (Horizontal Pod Autoscaler)
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  minReplicas: 2          # Never less than 2
  maxReplicas: 10         # Never more than 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70    # Scale when CPU > 70%

---
# =================== WHAT HAPPENS ===================

# Normal load:
# - 2 pods running
# - Each pod uses ~30% CPU
# - Everything fine ✅

# High load:
# - CPU usage rises to 80%
# - HPA creates more pods
# - Load spreads across pods
# - CPU drops back to ~70%
# - Users happy ✅

# Low load:
# - CPU usage drops to 20%
# - HPA waits 5 minutes
# - Removes some pods
# - Saves resources ✅

---
# =================== SIMPLE COMMANDS ===================

# Install metrics-server (if needed):
# kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Deploy everything:
# kubectl apply -f this-file.yaml

# Check if working:
# kubectl get hpa
# kubectl get pods

# Test scaling:
# kubectl run load-test --image=busybox --restart=Never -- /bin/sh -c "while true; do wget -q -O- http://my-app-service; done"

# Watch scaling:
# kubectl get hpa --watch
# kubectl get pods --watch

# Clean up:
# kubectl delete pod load-test

---
# =================== SIMPLE TROUBLESHOOTING ===================

# HPA shows "unknown" metrics:
# - Install metrics-server
# - Check: kubectl top nodes

# HPA not scaling:
# - Check: kubectl describe hpa my-app-hpa
# - Make sure resource requests are set
# - Generate actual load to test

# Pods restarting:
# - Check resource limits
# - Look at pod logs
# - Maybe CPU/memory too low

---
# =================== SIMPLE RULES ===================

# 1. Always set resource requests
#    - HPA needs this to calculate percentages
#    - Start with realistic guesses

# 2. Start with CPU autoscaling
#    - Most apps are CPU-bound
#    - Memory scaling is trickier

# 3. Set reasonable limits
#    - minReplicas: 2+ (for availability)
#    - maxReplicas: Don't go crazy
#    - Target: 70% is usually good

# 4. Test your scaling
#    - Generate load and watch
#    - Adjust settings based on results

---
# =================== THAT'S IT! ===================

# This covers 90% of autoscaling needs:
# - More pods when busy
# - Fewer pods when idle
# - Saves money and improves performance
# - Works for most web applications

# Advanced stuff (only if you need it):
# - Memory-based scaling
# - Custom metrics
# - Vertical scaling (bigger pods)
# - But start simple!