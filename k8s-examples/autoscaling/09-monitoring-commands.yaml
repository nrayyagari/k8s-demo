# Essential Monitoring Commands for HPA and VPA Metrics
# WHY: You need to see what the autoscalers actually see
# HOW: These commands show the real data behind scaling decisions

# =================== HPA MONITORING COMMANDS ===================

# 1. Check HPA status with current metrics
# kubectl get hpa
# kubectl get hpa <hpa-name>
# kubectl get hpa <hpa-name> --watch

# Example output:
# NAME     REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
# web-hpa  Deployment/web-app 45%/70%   2         10        3          5m
#                             ↑   ↑
#                         current target

# 2. Detailed HPA information
# kubectl describe hpa <hpa-name>

# Look for this section:
# Metrics:                               ( current / target )
#   resource cpu on pods  (as a percentage of request):  45% (67m) / 70%
#                                                         ↑    ↑     ↑
#                                                   percentage actual target
# Events:
#   Normal  SuccessfulRescale  2m   horizontal-pod-autoscaler  New size: 3; reason: cpu resource utilization (percentage of request) above target

# 3. Raw HPA data in YAML format
# kubectl get hpa <hpa-name> -o yaml

# Key sections to look for:
# status:
#   currentMetrics:
#   - resource:
#       current:
#         averageUtilization: 45    # (actual usage / request) × 100
#         averageValue: 67m         # actual CPU usage across all pods
#       name: cpu
#     type: Resource
#   currentReplicas: 3
#   desiredReplicas: 3

# =================== VPA MONITORING COMMANDS ===================

# 1. Check VPA status
# kubectl get vpa
# kubectl get vpa <vpa-name>

# Example output:
# NAME      MODE   CPU    MEM       PROVIDED   AGE
# web-vpa   Auto   142m   268435456 True       10m

# 2. Detailed VPA recommendations
# kubectl describe vpa <vpa-name>

# Look for this section:
# Recommendation:
#   Container Recommendations:
#     Container Name:  web-app
#     Lower Bound:
#       Cpu:     25m      # Minimum recommended
#       Memory:  134217728 # 128Mi in bytes
#     Target:
#       Cpu:     142m     # Optimal recommendation
#       Memory:  268435456 # 256Mi in bytes
#     Uncapped Target:
#       Cpu:     142m
#       Memory:  268435456
#     Upper Bound:
#       Cpu:     101770m  # Maximum recommended
#       Memory:  1576550k

# 3. Raw VPA data in YAML format
# kubectl get vpa <vpa-name> -o yaml

# Key sections:
# status:
#   recommendation:
#     containerRecommendations:
#     - containerName: web-app
#       lowerBound:
#         cpu: 25m
#         memory: 134217728
#       target:
#         cpu: 142m
#         memory: 268435456
#       upperBound:
#         cpu: 101770m
#         memory: 1576550k

# =================== ACTUAL RESOURCE USAGE COMMANDS ===================

# 1. Current pod resource usage
# kubectl top pods
# kubectl top pods -l app=<app-name>
# kubectl top pods --sort-by=cpu
# kubectl top pods --sort-by=memory

# Example output:
# NAME                   CPU(cores)   MEMORY(bytes)
# web-app-abc123         67m          150Mi
# web-app-def456         72m          145Mi
# web-app-ghi789         58m          160Mi

# 2. Node resource usage
# kubectl top nodes

# Example output:
# NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
# node-1     523m         26%    2048Mi          53%
# node-2     445m         22%    1824Mi          47%

# 3. Detailed pod resource information
# kubectl describe pod <pod-name>

# Look for:
# Containers:
#   web-app:
#     Limits:
#       cpu:     500m
#       memory:  512Mi
#     Requests:
#       cpu:        100m    # HPA uses this for calculations
#       memory:     128Mi   # HPA uses this for calculations

# =================== METRICS API DEBUGGING ===================

# 1. Check if metrics-server is running
# kubectl get pods -n kube-system | grep metrics-server

# 2. Test metrics API directly (raw API calls)
# kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes | jq .
# kubectl get --raw /apis/metrics.k8s.io/v1beta1/pods | jq .

# 3. Get metrics for specific namespace
# kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespaces/default/pods | jq .

# 4. Check custom metrics API (if installed)
# kubectl get --raw /apis/custom.metrics.k8s.io/v1beta1 | jq .

# 5. Check external metrics API (if installed)  
# kubectl get --raw /apis/external.metrics.k8s.io/v1beta1 | jq .

# =================== REAL-TIME MONITORING ===================

# 1. Watch HPA scaling in real-time
# kubectl get hpa --watch
# kubectl get pods -l app=<app-name> --watch

# 2. Monitor resource usage continuously
# watch kubectl top pods -l app=<app-name>

# 3. Follow HPA events
# kubectl get events --field-selector involvedObject.kind=HorizontalPodAutoscaler --watch

# 4. Monitor VPA recommendations over time
# watch kubectl describe vpa <vpa-name>

# =================== TROUBLESHOOTING COMMANDS ===================

# HPA not working?
# kubectl describe hpa <hpa-name>
# kubectl get --raw /apis/metrics.k8s.io/v1beta1/pods
# kubectl logs -n kube-system deployment/metrics-server

# VPA not working?
# kubectl get pods -n vpa-system
# kubectl logs -n vpa-system deployment/vpa-recommender
# kubectl logs -n vpa-system deployment/vpa-updater

# =================== EXAMPLE MONITORING SESSION ===================

# Terminal 1: Watch HPA scaling
# kubectl get hpa web-hpa --watch

# Terminal 2: Watch pod count changes
# kubectl get pods -l app=web-app --watch

# Terminal 3: Monitor resource usage
# watch kubectl top pods -l app=web-app

# Terminal 4: Generate load (to trigger scaling)
# kubectl run load-generator --image=busybox --restart=Never -- /bin/sh -c "while true; do wget -q -O- http://web-service; done"

# What you'll see:
# 1. Load increases → CPU usage rises
# 2. HPA detects high utilization → scales up
# 3. More pods → load distributes → CPU usage drops
# 4. HPA stabilizes at new replica count

# =================== KEY TAKEAWAYS ===================

# HPA monitors:
# - Current CPU/memory usage (from metrics-server)
# - Calculates: (current usage / resource request) × 100
# - Makes scaling decisions every 15 seconds

# VPA monitors:
# - Historical usage patterns (from kubelet)
# - Analyzes trends over time
# - Provides resource recommendations

# Both need:
# - Proper resource requests configured
# - Metrics-server running for HPA
# - VPA components installed for VPA

# The "utilization" is always relative to resource REQUESTS, not limits or node capacity!