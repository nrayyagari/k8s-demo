# Egress Traffic Control - Prevent Data Exfiltration
# Control outbound traffic from pods to external services

---
# Namespace for egress control demo
apiVersion: v1
kind: Namespace
metadata:
  name: egress-demo
  labels:
    security-level: high
    egress-control: enabled

---
# Application that needs controlled external access
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app
  namespace: egress-demo
  labels:
    app: secure-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: secure-app
  template:
    metadata:
      labels:
        app: secure-app
        role: application
        security-zone: restricted
    spec:
      containers:
      - name: app
        image: nginx:1.27
        ports:
        - containerPort: 80

---
# Service for the application
apiVersion: v1
kind: Service
metadata:
  name: secure-app-service
  namespace: egress-demo
spec:
  selector:
    app: secure-app
  ports:
  - port: 80

---
# Test clients with different security levels
apiVersion: v1
kind: Pod
metadata:
  name: restricted-client
  namespace: egress-demo
  labels:
    app: test-client
    security-zone: restricted
    role: application
spec:
  containers:
  - name: client
    image: busybox:1.36
    command: ["sleep", "3600"]

---
apiVersion: v1
kind: Pod
metadata:
  name: privileged-client
  namespace: egress-demo
  labels:
    app: test-client
    security-zone: privileged
    role: admin
spec:
  containers:
  - name: client
    image: busybox:1.36
    command: ["sleep", "3600"]

---
# Internal service that should be accessible
apiVersion: v1
kind: Pod
metadata:
  name: internal-api
  namespace: egress-demo
  labels:
    app: internal-api
    role: internal-service
spec:
  containers:
  - name: api
    image: httpd:2.4
    ports:
    - containerPort: 80

---
apiVersion: v1
kind: Service
metadata:
  name: internal-api-service
  namespace: egress-demo
spec:
  selector:
    app: internal-api
  ports:
  - port: 80

---
# NETWORK POLICY: Default deny all egress
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-egress
  namespace: egress-demo
  annotations:
    description: "Block all outbound traffic by default"
spec:
  podSelector: {}  # Apply to all pods
  policyTypes:
  - Egress
  # No egress rules = deny all egress

---
# NETWORK POLICY: Allow DNS resolution
# Essential for service discovery
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-dns-egress
  namespace: egress-demo
  annotations:
    description: "Allow DNS queries for service discovery"
spec:
  podSelector: {}
  policyTypes:
  - Egress
  egress:
  # Allow DNS to kube-dns/CoreDNS
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 53

---
# NETWORK POLICY: Allow internal cluster communication
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-internal-egress
  namespace: egress-demo
  annotations:
    description: "Allow communication within cluster"
spec:
  podSelector: {}
  policyTypes:
  - Egress
  egress:
  # Allow traffic within same namespace
  - to:
    - podSelector: {}
  # Allow traffic to other namespaces (for shared services)
  - to:
    - namespaceSelector: {}

---
# NETWORK POLICY: Allow specific external services
# Whitelist approved external APIs
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-approved-external
  namespace: egress-demo
  annotations:
    description: "Allow access to approved external services only"
spec:
  podSelector:
    matchLabels:
      security-zone: restricted
  policyTypes:
  - Egress
  egress:
  # Allow HTTPS to approved external APIs
  - to:
    - ipBlock:
        cidr: 0.0.0.0/0
        except:
        - 169.254.169.254/32  # Block AWS metadata service
        - 10.0.0.0/8          # Block internal RFC1918
        - 172.16.0.0/12       # Block internal RFC1918
        - 192.168.0.0/16      # Block internal RFC1918
    ports:
    - protocol: TCP
      port: 443  # HTTPS only
  # Allow HTTP to specific approved services
  - to:
    - ipBlock:
        cidr: 8.8.8.8/32  # Google DNS (example approved service)
    ports:
    - protocol: TCP
      port: 80
    - protocol: UDP
      port: 53

---
# NETWORK POLICY: Privileged pods get more access
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-privileged-external
  namespace: egress-demo
  annotations:
    description: "Allow broader external access for privileged pods"
spec:
  podSelector:
    matchLabels:
      security-zone: privileged
  policyTypes:
  - Egress
  egress:
  # Allow all external traffic for privileged pods
  - to:
    - ipBlock:
        cidr: 0.0.0.0/0
        except:
        - 169.254.169.254/32  # Still block metadata service
    ports:
    - protocol: TCP
      port: 80
    - protocol: TCP
      port: 443
    - protocol: TCP
      port: 22   # SSH
    - protocol: TCP
      port: 3306 # MySQL
    - protocol: TCP
      port: 5432 # PostgreSQL

---
# NETWORK POLICY: Block metadata service access
# Prevent pods from accessing cloud provider metadata
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: block-metadata-service
  namespace: egress-demo
  annotations:
    description: "Explicitly block access to cloud metadata services"
spec:
  podSelector: {}
  policyTypes:
  - Egress
  egress:
  # Explicitly deny metadata service
  - to:
    - ipBlock:
        cidr: 169.254.169.254/32
    # No ports specified = deny all ports

# EXPLANATION:
#
# Egress Control Strategy:
# 1. Default deny all outbound traffic
# 2. Allow essential services (DNS, internal cluster)
# 3. Whitelist specific external services
# 4. Different policies for different security zones
# 5. Explicitly block dangerous endpoints
#
# Security Benefits:
# - Prevents data exfiltration
# - Limits attack surface if pods are compromised
# - Controls which external services can be accessed
# - Prevents access to cloud metadata services
#
# Common Use Cases:
# - PCI compliance (restrict payment processing pods)
# - Preventing insider threats
# - Compliance with data locality requirements
# - Limiting blast radius of supply chain attacks

# TESTING COMMANDS:
#
# 1. Deploy egress control demo:
# kubectl apply -f 05-egress-control.yaml
#
# 2. Wait for pods to be ready:
# kubectl get pods -n egress-demo -w
#
# 3. Test DNS resolution (should work - explicitly allowed):
# kubectl exec -it restricted-client -n egress-demo -- nslookup google.com
# kubectl exec -it restricted-client -n egress-demo -- nslookup internal-api-service
#
# 4. Test internal cluster communication (should work):
# kubectl exec -it restricted-client -n egress-demo -- nc -zv internal-api-service 80
# kubectl exec -it restricted-client -n egress-demo -- wget -qO- http://internal-api-service --timeout=5
#
# 5. Test approved external HTTPS (should work):
# kubectl exec -it restricted-client -n egress-demo -- wget -qO- https://httpbin.org/get --timeout=10
#
# 6. Test blocked external HTTP (should fail):
# kubectl exec -it restricted-client -n egress-demo -- wget -qO- http://httpbin.org/get --timeout=5
#
# 7. Test metadata service access (should fail):
# kubectl exec -it restricted-client -n egress-demo -- wget -qO- http://169.254.169.254/latest/meta-data/ --timeout=5
#
# 8. Test privileged pod access (should work):
# kubectl exec -it privileged-client -n egress-demo -- wget -qO- http://httpbin.org/get --timeout=10
# kubectl exec -it privileged-client -n egress-demo -- nc -zv google.com 22
#
# 9. Test without egress policy (compare before/after):
# kubectl delete networkpolicy default-deny-egress -n egress-demo
# kubectl exec -it restricted-client -n egress-demo -- wget -qO- http://httpbin.org/get --timeout=5
# kubectl apply -f 05-egress-control.yaml  # Restore policy
#
# 10. View all egress policies:
# kubectl get networkpolicy -n egress-demo
# kubectl describe networkpolicy allow-approved-external -n egress-demo